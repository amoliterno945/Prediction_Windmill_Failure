{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anthony\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA % in prominent variables: \n",
      " sensor_8      0.072091\n",
      "sensor_87     0.011071\n",
      "sensor_97     1.000000\n",
      "sensor_140    0.010384\n",
      "sensor_167    0.011071\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Nas remaining 0\n"
     ]
    }
   ],
   "source": [
    "dat1=\"C:/Users/Anthony/Desktop/Uptake Data Science Case Question/training.csv\"\n",
    "weather1=\"C:/Users/Anthony/Desktop/Uptake Data Science Case Question/weather.csv\"\n",
    "test1=\"C:/Users/Anthony/Desktop/Uptake Data Science Case Question/testing.csv\"\n",
    "revenue1=\"C:/Users/Anthony/Desktop/Uptake Data Science Case Question/revenue.csv\"\n",
    "\n",
    "dat=pd.read_csv(dat1)\n",
    "test=pd.read_csv(test1)\n",
    "weather=pd.read_csv(weather1)\n",
    "revenue=pd.read_csv(revenue1)\n",
    "\n",
    "#Reorder columns so prominent variables first:\n",
    "cols=['id','site','inspect']+list(test)[:-3]\n",
    "test=test[cols]\n",
    "\n",
    "cols= ['id','site','status','repair_cost'] + list(dat)[:-4]\n",
    "dat=dat[cols]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#MERGE TRAIN AND WEATHER\n",
    "\n",
    "#Reformat weather's \"site\" column to only include site number (instead of string)\n",
    "weather_sites=[]\n",
    "for i in weather.loc[:,'site']:\n",
    "    weather_sites.append(int(i.split(\"_\")[1]))\n",
    "\n",
    "for i in range(len(weather.loc[:,\"site\"])):\n",
    "    weather.loc[i,\"site\"] = weather_sites[i]\n",
    "\n",
    "#Merge with train data set\n",
    "dat = dat.merge(weather,on='site')\n",
    "\n",
    "#ENCODING\n",
    "\n",
    "#Make 'status' have 1=online, 0=break\n",
    "dat.loc[:,'status'] = LabelBinarizer().fit_transform(dat.loc[:,'status'])\n",
    "\n",
    "\n",
    "#Lightning\n",
    "dat[\"lightning_prob\"]=dat[\"lightning_prob\"].fillna(value=\"None\")\n",
    "dat=pd.concat((dat,pd.get_dummies(dat.loc[:,'lightning_prob'])), axis=1)\n",
    "dat = dat.drop(['lightning_prob'], axis = 1)\n",
    "#rename\n",
    "cols = list(dat)[:-3] + ['Lightning_High', 'Lightning_Low', 'Lightning_None']\n",
    "dat.columns = cols\n",
    "\n",
    "\n",
    "#Encode sensor_97 \n",
    "dat=pd.concat((dat,pd.get_dummies(dat.loc[:,'sensor_97'])), axis=1)\n",
    "dat = dat.drop(['sensor_97'], axis = 1)\n",
    "\n",
    "#Encode precipitation\n",
    "dat=pd.concat((dat,pd.get_dummies(dat.loc[:,'precipitation'])), axis=1)\n",
    "dat = dat.drop(['precipitation'], axis = 1)\n",
    "\n",
    "\n",
    "#Encode sensor_21 (i.e. long list of codes)\n",
    "dat=pd.concat((dat,pd.get_dummies(dat.loc[:,'sensor_21'])), axis=1)\n",
    "dat=dat.drop(['sensor_21'], axis = 1)\n",
    "\n",
    "\n",
    "#Encode site (i.e. long list of codes)\n",
    "dat=pd.concat((dat,pd.get_dummies(dat.loc[:,'site'])), axis=1)\n",
    "site_ref_dat=dat.loc[:,'site'].copy() #Used to join with predictions at end for profit calc\n",
    "dat=dat.drop(['site'], axis = 1)\n",
    "# cols = list(dat)[:370] + ????\n",
    "# dat.columns = cols\n",
    "\n",
    "\n",
    "#Remove \n",
    "dat=dat.drop(['sensor_5','sensor_146','sensor_153','sensor_1'], axis = 1) \n",
    "\n",
    "\n",
    "\n",
    "#Impute\n",
    "#Fill in no repair cost with zero\n",
    "dat[\"repair_cost\"]=dat[\"repair_cost\"].fillna(value=0)\n",
    "\n",
    "\n",
    "#NA analysis\n",
    "# #What % of each column are NA values?\n",
    "y=pd.DataFrame(dat.isnull().sum()/len(dat.index)).sort_values(by=0,ascending=False)\n",
    "plt.bar(np.array(range(len(y.index))),np.array(y.loc[:,0]))\n",
    "plt.show()\n",
    "\n",
    "#Rank of % having NaN -  guided variables of importance\n",
    "print(\"NA % in prominent variables:\",\"\\n\" ,dat.loc[:,[\"sensor_8\",\"sensor_87\",\"sensor_97\",\"sensor_140\",\"sensor_167\"]].isnull().sum()/len(dat.index))\n",
    "\n",
    "#Dropping high NA variables\n",
    "vars_to_drop=list(y.loc[list(y.loc[:,0]>.25),:].index)\n",
    "dat = dat.drop(vars_to_drop, axis = 1)\n",
    "\n",
    "# #Impute rest of NAs\n",
    "for i in list(dat)[2:]:\n",
    "#     print(i)\n",
    "    k=dat.loc[:,i].isnull().sum() #number of NAs to fill\n",
    "#     print(k)\n",
    "    try:\n",
    "        if k != 0:      \n",
    "            no_na_dat=list(dat.loc[dat.loc[:,i].notna(),i])\n",
    "            fill_list = lambda x: random.choices(no_na_dat,k=k)\n",
    "            fill_list = fill_list(no_na_dat)\n",
    "            dat.loc[:,i] = dat.loc[:,i].fillna(pd.Series(np.random.choice(fill_list, size=len(dat.index))))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Nas remaining\",np.sum(dat.isnull().sum()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST data\n",
    "\n",
    "#Prep test data for prediction:\n",
    "\n",
    "#Merge weather\n",
    "test = test.merge(weather,on='site')\n",
    "\n",
    "\n",
    "#ENCODING\n",
    "\n",
    "\n",
    "#Lightning\n",
    "test[\"lightning_prob\"]=test[\"lightning_prob\"].fillna(value=\"None\")\n",
    "test=pd.concat((test,pd.get_dummies(test.loc[:,'lightning_prob'])), axis=1)\n",
    "test = test.drop(['lightning_prob'], axis = 1)\n",
    "#rename\n",
    "cols = list(test)[:-3] + ['Lightning_High', 'Lightning_Low', 'Lightning_None']\n",
    "test.columns = cols\n",
    "\n",
    "\n",
    "#Encode sensor_97 \n",
    "test=pd.concat((test,pd.get_dummies(test.loc[:,'sensor_97'])), axis=1)\n",
    "test = test.drop(['sensor_97'], axis = 1)\n",
    "\n",
    "#Encode precipitation\n",
    "test=pd.concat((test,pd.get_dummies(test.loc[:,'precipitation'])), axis=1)\n",
    "test = test.drop(['precipitation'], axis = 1)\n",
    "\n",
    "#Encode sensor_21 (i.e. long list of codes)\n",
    "test=pd.concat((test,pd.get_dummies(test.loc[:,'sensor_21'])), axis=1)\n",
    "test=test.drop(['sensor_21'], axis = 1)\n",
    "\n",
    "#Encode site (i.e. long list of codes)\n",
    "site_ref=test.loc[:,'site'].copy()\n",
    "test=pd.concat((test,pd.get_dummies(test.loc[:,'site'])), axis=1)\n",
    "test=test.drop(['site'], axis = 1)\n",
    "\n",
    "#Remove for convenience\n",
    "test=test.drop(['sensor_5','sensor_146','sensor_153','sensor_1'], axis = 1)\n",
    "\n",
    "\n",
    "#Dropping high NA variables\n",
    "y=pd.DataFrame(test.isnull().sum()/len(test.index)).sort_values(by=0,ascending=False)\n",
    "vars_to_drop=list(y.loc[list(y.loc[:,0]>.25),:].index)\n",
    "test = test.drop(vars_to_drop, axis = 1)\n",
    "\n",
    "\n",
    "# #Impute rest of NAs\n",
    "for i in list(test)[2:]:\n",
    "    k=test[i].isnull().sum() #number of NAs to fill\n",
    "    try:\n",
    "        if k != 0:      \n",
    "            no_na_dat=list(test.loc[test[i].notna(),i])\n",
    "            fill_list = lambda x: random.choices(no_na_dat,k=k)\n",
    "            fill_list = fill_list(no_na_dat)\n",
    "            test.loc[:,i] = test.loc[:,i].fillna(pd.Series(np.random.choice(fill_list, size=len(test.index))))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "#reattach site ref\n",
    "\n",
    "test=pd.concat((site_ref,test),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fault_code_7FW90',\n",
       " 'fault_code_KME1K',\n",
       " 'fault_code_WQR5C',\n",
       " 'fault_code_ZK6DM',\n",
       " 'fault_code_ZNG46']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What does train have that test does not\n",
    "reconcile_vars1=[]\n",
    "for i in list(dat)[3:]:\n",
    "    if i not in list(test)[3:]:\n",
    "        reconcile_vars1.append(i)\n",
    "reconcile_vars1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fault_code_0I5C7',\n",
       " 'fault_code_3CU2K',\n",
       " 'fault_code_7O1V1',\n",
       " 'fault_code_8C6PZ',\n",
       " 'fault_code_8EF6Z',\n",
       " 'fault_code_B5X9U',\n",
       " 'fault_code_BDXFH',\n",
       " 'fault_code_BIXGE',\n",
       " 'fault_code_BLBOS',\n",
       " 'fault_code_C2Z8I',\n",
       " 'fault_code_CKS0W',\n",
       " 'fault_code_E8YVI',\n",
       " 'fault_code_EELFJ',\n",
       " 'fault_code_EUZ2V',\n",
       " 'fault_code_GOPHO',\n",
       " 'fault_code_HQRE7',\n",
       " 'fault_code_JGET4',\n",
       " 'fault_code_JLY5T',\n",
       " 'fault_code_KS5XY',\n",
       " 'fault_code_KZV2U',\n",
       " 'fault_code_LBSEC',\n",
       " 'fault_code_LDB3R',\n",
       " 'fault_code_LHKVQ',\n",
       " 'fault_code_LPUBG',\n",
       " 'fault_code_LZPA8',\n",
       " 'fault_code_M2L9T',\n",
       " 'fault_code_M5DU3',\n",
       " 'fault_code_MIQJR',\n",
       " 'fault_code_MPJZ5',\n",
       " 'fault_code_R30RL',\n",
       " 'fault_code_SKOC8',\n",
       " 'fault_code_T3JGB',\n",
       " 'fault_code_VM08E',\n",
       " 'fault_code_VR23X',\n",
       " 'fault_code_WE65I',\n",
       " 'fault_code_XPH15',\n",
       " 'fault_code_ZAW7L',\n",
       " 5,\n",
       " 62,\n",
       " 71]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What does test have that train does not\n",
    "reconcile_vars2=[]\n",
    "for i in list(test)[4:]:\n",
    "    if i not in list(dat)[3:]:\n",
    "        reconcile_vars2.append(i)\n",
    "        \n",
    "reconcile_vars2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat=dat.drop(reconcile_vars1, axis = 1)\n",
    "test=test.drop(reconcile_vars2, axis = 1)\n",
    "list(dat)[3:]==list(test)[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data\n",
    "train, val = train_test_split(dat, test_size = 0.2, random_state = 43)\n",
    "\n",
    "#Put aside: ID, status, repair_cost\n",
    "train_aside=train.iloc[:,:3]\n",
    "val_aside=val.iloc[:,:3]\n",
    "\n",
    "#Predictors\n",
    "x_train=train.iloc[:,3:]\n",
    "x_val=val.iloc[:,3:]\n",
    "\n",
    "#Results\n",
    "y_train = train.iloc[:,1]\n",
    "y_val= val.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anthony\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9321, 754) (2331, 754) (9321,) (2331,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anthony\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Anthony\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Scale the data\n",
    "std_scale = StandardScaler().fit(x_train)\n",
    "train_standardized = std_scale.transform(x_train) \n",
    "test_standardized=std_scale.transform(x_val) \n",
    "\n",
    "\n",
    "print(x_train.shape,x_val.shape,y_train.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9321, 10)"
      ]
     },
     "execution_count": 1365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(x_train)\n",
    "x_train_pca=pca.transform(x_train)\n",
    "x_test_pca=pca.transform(x_val)\n",
    "x_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99638379, 0.99794734, 0.99825344, 0.9984765 , 0.99867899,\n",
       "       0.99885048, 0.99900527, 0.99913534, 0.99924814, 0.99934291])"
      ]
     },
     "execution_count": 1366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First loading looks well to explain\n",
    "pca.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9794079794079794"
      ]
     },
     "execution_count": 1270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN=KNeighborsClassifier(n_neighbors=5, \n",
    "                     weights='uniform', \n",
    "                     algorithm='auto', #Automatically determines best method: Ball or KDTree\n",
    "                     leaf_size=30, #For Ball tree or KDtree methods\n",
    "                     p=2, #Euclidean distance\n",
    "                     metric='minkowski', #If p=2 then this is just euclidean\n",
    "                     metric_params=None, #Additional args (dict) for metric..\n",
    "                     n_jobs=1)\n",
    "\n",
    "KNN.fit(x_train,y_train)\n",
    "KNN.score(x_val,y_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9764049764049764"
      ]
     },
     "execution_count": 1399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytree=DecisionTreeClassifier(criterion='gini', \n",
    "                       splitter='best', \n",
    "                       max_depth=None, \n",
    "                       min_samples_split=2, \n",
    "                       min_samples_leaf=1, \n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       max_features=None, \n",
    "                       random_state=None, \n",
    "                       max_leaf_nodes=None, \n",
    "                       min_impurity_decrease=0.0, \n",
    "                       min_impurity_split=None, \n",
    "                       class_weight=None, \n",
    "                       presort=False)\n",
    "\n",
    "\n",
    "mytree.fit(x_train,y_train)\n",
    "mytree.score(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anthony\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9266409266409267"
      ]
     },
     "execution_count": 1272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC=LinearSVC(penalty='l2', \n",
    "              loss='squared_hinge', \n",
    "              dual=True, \n",
    "              tol=0.0001, \n",
    "              C=1.0, \n",
    "              multi_class='ovr', \n",
    "              fit_intercept=True, \n",
    "              intercept_scaling=1, \n",
    "              class_weight=None, \n",
    "              verbose=0, \n",
    "              random_state=None, \n",
    "              max_iter=1000)\n",
    "       \n",
    "    \n",
    "SVC.fit(x_train,y_train)\n",
    "SVC.score(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9553839553839554"
      ]
     },
     "execution_count": 1273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP=MLPClassifier(hidden_layer_sizes=(200,200,200,100), \n",
    "                  activation='relu', #maybe Logistic?\n",
    "                  solver='adam', #Adam optimizer works best for large sets, or ‘lbfgs’ for smaller ones.\n",
    "                  alpha=0.0001, #L2 Regularization parameter to shrink parameters\n",
    "                  batch_size='auto', \n",
    "                  learning_rate='constant', #maybe try ’adaptive’?\n",
    "                  learning_rate_init=0.001, \n",
    "                  power_t=0.5, #The exponent for inverse scaling learning rate. Only used for sgd solver...\n",
    "                  max_iter=200, \n",
    "                  shuffle=True, #shuffle samples before each iteration\n",
    "                  random_state=None, \n",
    "                  tol=0.0001, \n",
    "                  verbose=False, \n",
    "                  warm_start=False, \n",
    "                  momentum=0.9, #0-1 float, Only used for sgd solver...\n",
    "                  nesterovs_momentum=True, #Only used for sgd solver...\n",
    "                  early_stopping=False, \n",
    "                  validation_fraction=0.1, #0-1 float, proportion of training aside for validation for early stopping.\n",
    "                  beta_1=0.9, #0-1 float, Exponential decay rate for estimates of 1st moment vector in adam\n",
    "                  beta_2=0.999, #0-1 float, Exponential decay rate for estimates of 2nd moment vector in adam\n",
    "                  epsilon=1e-08)\n",
    "\n",
    "MLP.fit(x_train,y_train)\n",
    "MLP.score(x_val,y_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anthony\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9768339768339769"
      ]
     },
     "execution_count": 1274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models=[(\"tree\",mytree),(\"knn\",KNN),(\"mlp\",MLP),(\"svc\",SVC)]\n",
    "\n",
    "ensemble=VotingClassifier(estimators=models, \n",
    "                          voting='hard', \n",
    "                          weights=None, \n",
    "                          n_jobs=None, \n",
    "                          flatten_transform=None)\n",
    "\n",
    "\n",
    "ensemble.fit(x_train,y_train)\n",
    "ensemble.score(x_val,y_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824109824109825\n"
     ]
    }
   ],
   "source": [
    "Bags=BaggingClassifier(base_estimator=mytree,  \n",
    "                  n_estimators=25, #How many to ensemble?\n",
    "                  max_samples=1.0, \n",
    "                  max_features=1.0, \n",
    "                  bootstrap=True, \n",
    "                  bootstrap_features=False, \n",
    "                  oob_score=True, \n",
    "                  warm_start=False, \n",
    "                  n_jobs=1, \n",
    "                  random_state=1, \n",
    "                  verbose=0)\n",
    "\n",
    "Bags.fit(x_train,y_train)\n",
    "print(Bags.score(x_val,y_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9772629772629773\n"
     ]
    }
   ],
   "source": [
    "boost=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5), \n",
    "                         n_estimators=10, \n",
    "                         learning_rate=1.0, \n",
    "                         algorithm='SAMME.R', \n",
    "                         random_state=None)\n",
    "\n",
    "boost.fit(x_train,y_train)\n",
    "print(boost.score(x_val,y_val)) #returns mean accuracy on TEST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's calculate expected profit\n",
    "#Profit predictors\n",
    "dat_whole=dat.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred0=boost.predict(dat_whole)\n",
    "\n",
    "#quickly switch predictions so 1=breakdown expected\n",
    "pred0=(pred0-1)*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11432,    18],\n",
       "       [   38,   164]], dtype=int64)"
      ]
     },
     "execution_count": 1371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true=(dat.iloc[:,1]-1)*-1\n",
    "\n",
    "confusion_matrix(y_true, pred0, labels=None, sample_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>repair_cost</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>sensor_9</th>\n",
       "      <th>sensor_10</th>\n",
       "      <th>sensor_11</th>\n",
       "      <th>...</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.611918e+03</td>\n",
       "      <td>-2.933241e+03</td>\n",
       "      <td>-9.041325</td>\n",
       "      <td>-1.765398e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6516.169849</td>\n",
       "      <td>-3.122919e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.929201e+07</td>\n",
       "      <td>1.084668e+07</td>\n",
       "      <td>52055.296635</td>\n",
       "      <td>2.632376e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10782.008509</td>\n",
       "      <td>6.079343e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.022624e+06</td>\n",
       "      <td>9.176105e+08</td>\n",
       "      <td>35.299704</td>\n",
       "      <td>-2.801914e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-452702.949386</td>\n",
       "      <td>4.566554e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.836212e+04</td>\n",
       "      <td>-3.356804e+02</td>\n",
       "      <td>36242.870180</td>\n",
       "      <td>-1.179606e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25394.463923</td>\n",
       "      <td>-4.575437e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.893529e+05</td>\n",
       "      <td>-1.488137e+03</td>\n",
       "      <td>8172.488031</td>\n",
       "      <td>5.433812e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1092.046899</td>\n",
       "      <td>4.585778e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 757 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  status  repair_cost      sensor_2      sensor_3      sensor_7  \\\n",
       "0   1       1          0.0 -9.611918e+03 -2.933241e+03     -9.041325   \n",
       "1  12       1          0.0  6.929201e+07  1.084668e+07  52055.296635   \n",
       "2  15       1          0.0 -1.022624e+06  9.176105e+08     35.299704   \n",
       "3  62       1          0.0 -1.836212e+04 -3.356804e+02  36242.870180   \n",
       "4  69       1          0.0  4.893529e+05 -1.488137e+03   8172.488031   \n",
       "\n",
       "       sensor_8  sensor_9      sensor_10     sensor_11 ...   306  307  308  \\\n",
       "0 -1.765398e+03       0.0    6516.169849 -3.122919e+01 ...     0    0    0   \n",
       "1  2.632376e+05       0.0  -10782.008509  6.079343e+04 ...     0    0    0   \n",
       "2 -2.801914e+03       0.0 -452702.949386  4.566554e+08 ...     0    0    0   \n",
       "3 -1.179606e+03       0.0  -25394.463923 -4.575437e+02 ...     0    0    0   \n",
       "4  5.433812e+06       0.0   -1092.046899  4.585778e+04 ...     0    0    0   \n",
       "\n",
       "   309  310  311  312  313  314  315  \n",
       "0    0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 757 columns]"
      ]
     },
     "execution_count": 1324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11652, 757)"
      ]
     },
     "execution_count": 1281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>repair_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site  id  status  repair_cost\n",
       "0    36   1       1          0.0\n",
       "1    36  12       1          0.0\n",
       "2    36  15       1          0.0\n",
       "3    36  62       1          0.0\n",
       "4    36  69       1          0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table=pd.concat((site_ref_dat,dat.iloc[:,:3]),axis=1)\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site  revenue\n",
       "0     1      204\n",
       "1     2      188\n",
       "2     3      235\n",
       "3     4      153\n",
       "4     5      140"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adjust sites to be by numbers not string\n",
    "revenue=pd.read_csv(revenue1)\n",
    "for i in range(315):\n",
    "    revenue.loc[i,'site'] = int(revenue.loc[i,'site'].split(\"_\")[1])\n",
    "    \n",
    "revenue.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table.merge(revenue,on='site')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=list(table)\n",
    "table = pd.concat((table,pd.DataFrame(pred0)),axis=1)\n",
    "table.columns = cols+[\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>repair_cost</th>\n",
       "      <th>revenue</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site  id  status  repair_cost  revenue  prediction\n",
       "0    36   1       1          0.0      145           0\n",
       "1    36  12       1          0.0      145           0\n",
       "2    36  15       1          0.0      145           0\n",
       "3    36  62       1          0.0      145           0\n",
       "4    36  69       1          0.0      145           0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2090558"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(table.revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1994406.0"
      ]
     },
     "execution_count": 1376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit_train=0\n",
    "\n",
    "for i in range(table.shape[0]):\n",
    "    if table.loc[i,\"prediction\"]==0 and table.loc[i,\"status\"]==1 : #working ok and predicted ok\n",
    "       profit_train=profit_train+table.loc[i,\"revenue\"]\n",
    "    elif table.loc[i,\"prediction\"]==0 and table.loc[i,\"status\"]==0 : #broke unpredictably\n",
    "        profit_train=profit_train+table.loc[i,\"revenue\"]-table.loc[i,\"repair_cost\"]\n",
    "    elif table.loc[i,\"prediction\"]==1 and table.loc[i,\"status\"]==1 : #expected repair\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    " \n",
    "profit_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-262748.0"
      ]
     },
     "execution_count": 1377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No model:\n",
    "rev=np.sum(revenue.loc[:,'revenue'])\n",
    "cost=np.sum(table.loc[:,'repair_cost'])\n",
    "rev-cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using model to predict TEST data\n",
    "\n",
    "#Making sure predictors match between train and test\n",
    "list(x_train)==list(test.iloc[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anthony\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Split data\n",
    "\n",
    "#Predictors\n",
    "test_x=test.iloc[:,3:]\n",
    "test_aside=test.iloc[:,:3]\n",
    "\n",
    "#Scale the data\n",
    "test_standardized=std_scale.transform(test_x) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=boost.predict(test_x)\n",
    "\n",
    "#quickly switch predictions so 1=breakdown expected\n",
    "pred=(pred-1)*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat rped df\n",
    "pred1=pd.DataFrame(pred)\n",
    "pred1.columns=[\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aside = test_aside.merge(revenue,on='site')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert predictions into \"inspect\"\n",
    "test_aside.loc[:,\"inspect\"]=pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>id</th>\n",
       "      <th>inspect</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>11653</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>11655</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>11679</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>11720</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>11768</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site     id  inspect  revenue\n",
       "0    46  11653        0      191\n",
       "1    46  11655        0      191\n",
       "2    46  11679        0      191\n",
       "3    46  11720        0      191\n",
       "4    46  11768        0      191"
      ]
     },
     "execution_count": 1384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_aside.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8290694"
      ]
     },
     "execution_count": 1385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit=0\n",
    "for i in range(test_aside.shape[0]):\n",
    "    if test_aside.loc[i,\"inspect\"]==0:\n",
    "       profit=profit+test_aside.loc[i,\"revenue\"]\n",
    "    else:\n",
    "        pass\n",
    " \n",
    "profit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
